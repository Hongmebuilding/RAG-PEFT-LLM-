{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Ïã§Ìñâ ÌõÑ Îü∞ÌÉÄÏûÑ > ÏÑ∏ÏÖò Îã§ÏãúÏãúÏûë ÌõÑ ÏïÑÎûòÏÖÄÎ∂ÄÌÑ∞ Ïã§ÌñâÌïòÍ∏∞\n",
        "!pip install -U -q datasets transformers fsspec\n",
        "!pip install -q sentence-transformers faiss-cpu matplotlib seaborn pandas numpy tqdm scikit-learn nltk python-Levenshtein"
      ],
      "metadata": {
        "id": "Slf8h4QRZQpR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4MSFNPHY8S-"
      },
      "source": [
        "1. **Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú Î∞è Ï§ÄÎπÑ**:\n",
        "   - tatsu-lab/alpaca\n",
        "   - yahma/alpaca-cleaned  \n",
        "   - databricks/databricks-dolly-15k\n",
        "   - Í∞Å Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Íµ¨Ï°∞ Î∂ÑÏÑù Î∞è ÌÜµÌï© Ìè¨Îß∑ÏúºÎ°ú Î≥ÄÌôò\n",
        "\n",
        "2. **Synthetic Deduplication Íµ¨ÌòÑ**:\n",
        "   - Exact Matching (Ìï¥Ïãú Í∏∞Î∞ò)\n",
        "   - Normalized Matching (Ï†ïÍ∑úÌôî Í∏∞Î∞ò)\n",
        "   - Edit Distance (Levenshtein Í±∞Î¶¨)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import re\n",
        "import Levenshtein\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import time\n",
        "import tracemalloc\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú Î∞è Íµ¨Ï°∞ ÌôïÏù∏\n",
        "ds1 = load_dataset(\"tatsu-lab/alpaca\")\n",
        "ds2 = load_dataset(\"yahma/alpaca-cleaned\")\n",
        "ds3 = load_dataset(\"databricks/databricks-dolly-15k\")\n",
        "# ds4 = load_dataset(\"timdettmers/openassistant-guanaco\")\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ÏÖã Í∞úÏàò ÌôïÏù∏\n",
        "print(\"tatsu-lab/alpaca:\", len(ds1[\"train\"]))\n",
        "print(\"yahma/alpaca-cleaned:\", len(ds2[\"train\"]))\n",
        "print(\"databricks/databricks-dolly-15k:\", len(ds3[\"train\"]))\n",
        "\n",
        "# ÏòàÏãú: train splitÎßå ÏÇ¥Ìé¥Î≥¥Í∏∞\n",
        "print(\"‚îÄ tatsu-lab/alpaca sample ‚îÄ\")\n",
        "print(ds1[\"train\"][0])\n",
        "print(\"\\n‚îÄ yahma/alpaca-cleaned sample ‚îÄ\")\n",
        "print(ds2[\"train\"][0])\n",
        "print(\"\\n‚îÄ databricks/databricks-dolly-15k sample ‚îÄ\")\n",
        "print(ds3[\"train\"][0])\n",
        "# print(\"\\n‚îÄ openassistant-guanaco sample ‚îÄ\")\n",
        "# print(ds4[\"train\"][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8wgbcUZdEIn",
        "outputId": "88da07a2-4589-422a-aae5-a76f124a7a85"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tatsu-lab/alpaca: 52002\n",
            "yahma/alpaca-cleaned: 51760\n",
            "databricks/databricks-dolly-15k: 15011\n",
            "‚îÄ tatsu-lab/alpaca sample ‚îÄ\n",
            "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n",
            "\n",
            "‚îÄ yahma/alpaca-cleaned sample ‚îÄ\n",
            "{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.', 'input': '', 'instruction': 'Give three tips for staying healthy.'}\n",
            "\n",
            "‚îÄ databricks/databricks-dolly-15k sample ‚îÄ\n",
            "{'instruction': 'When did Virgin Australia start operating?', 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\", 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.', 'category': 'closed_qa'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Í≥µÌÜµ Ìè¨Îß∑ Î≥ÄÌôò (instruction, input, output)\n",
        "def unify(ds, cols_map):\n",
        "    df = pd.DataFrame(ds)\n",
        "    df = df.rename(columns=cols_map)[list(cols_map.values())]\n",
        "    return df\n",
        "\n",
        "df1 = unify(ds1[\"train\"], {\"instruction\": \"instruction\", \"input\": \"input\", \"output\": \"output\"})\n",
        "df2 = unify(ds2[\"train\"], {\"instruction\": \"instruction\", \"input\": \"input\", \"output\": \"output\"})\n",
        "df3 = unify(ds3[\"train\"], {\"instruction\": \"instruction\",  \"context\": \"input\", \"response\": \"output\"})\n",
        "# df4 = unify(ds4[\"train\"], {\"instruction\": \"instruction\", \"input\": \"input\",   \"output\": \"response\"})\n",
        "\n",
        "df_all = pd.concat([df1, df2, df3, ], ignore_index=True)\n",
        "print(\"ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¨Í∏∞:\", df_all.shape)\n",
        "print(df_all.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCeAtjJbdJHw",
        "outputId": "6915f5bf-4e60-4755-f955-6fda138b5b22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¨Í∏∞: (118773, 3)\n",
            "                            instruction input  \\\n",
            "0  Give three tips for staying healthy.         \n",
            "1    What are the three primary colors?         \n",
            "2    Describe the structure of an atom.         \n",
            "\n",
            "                                              output  \n",
            "0  1.Eat a balanced diet and make sure to include...  \n",
            "1  The three primary colors are red, blue, and ye...  \n",
            "2  An atom is made up of a nucleus, which contain...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic Deduplication - Exact Matching (Ìï¥Ïãú Í∏∞Î∞ò)\n",
        "def hash_text(row):\n",
        "    return hashlib.md5((row.instruction + row.input + row.output).encode()).hexdigest()\n",
        "\n",
        "df_all[\"hash\"] = df_all.apply(hash_text, axis=1)\n",
        "before = len(df_all)\n",
        "df_exact = df_all.drop_duplicates(\"hash\")\n",
        "after = len(df_exact)\n",
        "print(f\"Exact Matching: Ï§ëÎ≥µ Ï†úÍ±∞ Ï†Ñ {before} ‚Üí Ï†úÍ±∞ ÌõÑ {after}\")\n",
        "print(f\"Ï†úÍ±∞ sample Ïàò: {before - after}\")\n",
        "print(f\"Ï†úÍ±∞ sample ÎπÑÏú®: {(before - after) / before * 100:.2f}%\")\n",
        "\n",
        "# Ï§ëÎ≥µÎç∞Ïù¥ÌÑ∞ ÏòàÏãú Ï∂úÎ†•\n",
        "dups_norm = df_all[df_all.duplicated(\"norm\", keep=False)]\n",
        "groups_norm = dups_norm.groupby(\"norm\")\n",
        "print(\"\\nüîç Normalized Matching Ï§ëÎ≥µ ÏòàÏãú (2Í∞ú Í∑∏Î£π):\")\n",
        "for i, (key, group) in enumerate(groups_norm):\n",
        "    if i >= 2:\n",
        "        break\n",
        "    print(f\"\\nÍ∑∏Î£π {i+1}:\")\n",
        "    for _, row in group.head(2).iterrows():\n",
        "        print(\"Instruction:\", row.instruction)\n",
        "        print(\"Input      :\", row.input)\n",
        "        print(\"Output     :\", row.output)\n",
        "        print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQaNzYqhg0fc",
        "outputId": "db58c054-7803-4b21-bd9b-34baccef6001"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Matching: Ï§ëÎ≥µ Ï†úÍ±∞ Ï†Ñ 118773 ‚Üí Ï†úÍ±∞ ÌõÑ 116922\n",
            "Ï†úÍ±∞ sample Ïàò: 1851\n",
            "Ï†úÍ±∞ sample ÎπÑÏú®: 1.56%\n",
            "\n",
            "üîç Normalized Matching Ï§ëÎ≥µ ÏòàÏãú (2Í∞ú Í∑∏Î£π):\n",
            "\n",
            "Í∑∏Î£π 1:\n",
            "Instruction: According to the given context, classify the following sentence into whether it is true or false\n",
            "Input      : Context: Life can be unfair\n",
            "Sentence: Life should always be fair\n",
            "Output     : False\n",
            "---\n",
            "Instruction: According to the given context, classify the following sentence into whether it is true or false\n",
            "Input      : Context: Life can be unfair\n",
            "Sentence: Life should always be fair\n",
            "Output     : False\n",
            "---\n",
            "\n",
            "Í∑∏Î£π 2:\n",
            "Instruction: According to the input sentence, create a list of words.\n",
            "Input      : \"The cat is black and white\"\n",
            "Output     : [\"The\", \"cat\", \"is\", \"black\", \"and\", \"white\"]\n",
            "---\n",
            "Instruction: According to the input sentence, create a list of words.\n",
            "Input      : \"The cat is black and white\"\n",
            "Output     : [\"The\", \"cat\", \"is\", \"black\", \"and\", \"white\"]\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic Deduplication - Normalized Matching (Ï†ïÍ∑úÌôî)\n",
        "def normalize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\W+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "df_exact[\"norm\"] = df_exact.instruction.map(normalize) + \"|\" + df_exact.input.map(normalize) + \"|\" + df_exact.output.map(normalize)\n",
        "before = len(df_exact)\n",
        "df_norm = df_exact.drop_duplicates(\"norm\")\n",
        "after = len(df_norm)\n",
        "print(f\"Normalized Matching: Ï§ëÎ≥µ Ï†úÍ±∞ Ï†Ñ {before} ‚Üí Ï†úÍ±∞ ÌõÑ {after}\")\n",
        "print(f\"Ï†úÍ±∞ sample Ïàò: {before - after}\")\n",
        "print(f\"Ï†úÍ±∞ sample ÎπÑÏú®: {(before - after) / before * 100:.2f}%\")\n",
        "\n",
        "# ‚Üì Ï†úÍ±∞Îêú ÏòàÏãú Ï∂úÎ†• ‚Üì\n",
        "# df_exact[df_exact.duplicated(\"norm\", False)].sort_values(\"norm\").head(10)\n",
        "\n",
        "# Ï§ëÎ≥µÎç∞Ïù¥ÌÑ∞ ÏòàÏãú Ï∂úÎ†•\n",
        "dups_norm = df_exact[df_exact.duplicated(\"norm\", keep=False)]\n",
        "groups_norm = dups_norm.groupby(\"norm\")\n",
        "print(\"\\nüîç Normalized Matching Ï§ëÎ≥µ ÏòàÏãú (2Í∞ú Í∑∏Î£π):\")\n",
        "for i, (key, group) in enumerate(groups_norm):\n",
        "    if i >= 2:\n",
        "        break\n",
        "    print(f\"\\nÍ∑∏Î£π {i+1}:\")\n",
        "    for _, row in group.head(2).iterrows():\n",
        "        print(\"Instruction:\", row.instruction)\n",
        "        print(\"Input      :\", row.input)\n",
        "        print(\"Output     :\", row.output)\n",
        "        print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvJ2vDdqhI7B",
        "outputId": "f7b3fd84-e859-4662-9aca-41d6d7006120"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Matching: Ï§ëÎ≥µ Ï†úÍ±∞ Ï†Ñ 116922 ‚Üí Ï†úÍ±∞ ÌõÑ 116200\n",
            "Ï†úÍ±∞ sample Ïàò: 722\n",
            "Ï†úÍ±∞ sample ÎπÑÏú®: 0.62%\n",
            "\n",
            "üîç Normalized Matching Ï§ëÎ≥µ ÏòàÏãú (2Í∞ú Í∑∏Î£π):\n",
            "\n",
            "Í∑∏Î£π 1:\n",
            "Instruction: Add 10 words that start with the letter ‚ÄòM‚Äô to the given list.\n",
            "Input      : bank, car, tree\n",
            "Output     : bank, car, tree, muffin, museum, melody, magnet, mascot, mop, machete, mattress\n",
            "---\n",
            "Instruction: Add 10 words that start with the letter \"M\" to the given list.\n",
            "Input      : bank, car, tree\n",
            "Output     : bank, car, tree, muffin, museum, melody, magnet, mascot, mop, machete, mattress\n",
            "---\n",
            "\n",
            "Í∑∏Î£π 2:\n",
            "Instruction: Add a comma in the appropriate place.\n",
            "Input      : The dog chased the cat across the yard\n",
            "Output     : The dog, chased the cat across the yard.\n",
            "---\n",
            "Instruction: Add a comma in the appropriate place.\n",
            "Input      : The dog chased the cat across the yard\n",
            "Output     : The dog chased the cat, across the yard.\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-35-718881863.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_exact[\"norm\"] = df_exact.instruction.map(normalize) + \"|\" + df_exact.input.map(normalize) + \"|\" + df_exact.output.map(normalize)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_exact[df_exact.duplicated(\"norm\", keep=False)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X9UeuGmrRPz",
        "outputId": "342cc04f-8537-4ede-e296-f5be7bb803eb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1444"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Synthetic Deduplication - Edit Distance (Levenshtein)\n",
        "def levenshtein_dedup_with_examples(df, threshold=5):\n",
        "    keep = []\n",
        "    dup_pairs = []\n",
        "    for idx, row in tqdm(df.iterrows(),total=len(df)):\n",
        "        text = row.instruction + row.input + row.output\n",
        "        is_dup = False\n",
        "        for j in keep:\n",
        "            other = df.loc[j]\n",
        "            dist = Levenshtein.distance(text, other.instruction + other.input + other.output)\n",
        "            if dist <= threshold:\n",
        "                is_dup = True\n",
        "                dup_pairs.append((j, idx))\n",
        "                break\n",
        "        if not is_dup:\n",
        "            keep.append(idx)\n",
        "    return df.loc[keep], dup_pairs\n",
        "\n",
        "# Í∞ÄÏÉÅÏùò Ï§ëÎ≥µÎç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
        "similar_df = pd.concat([df_exact[df_exact.duplicated(\"norm\", keep=False)], df_exact.sample(100)])\n",
        "\n",
        "start = time.time()\n",
        "# df_edit = levenshtein_dedup_with_examples(df_norm_sample, threshold=20)\n",
        "df_edit, dup_pairs = levenshtein_dedup_with_examples(similar_df, threshold=20)\n",
        "elapsed = time.time() - start\n",
        "\n",
        "before=len(similar_df)\n",
        "after=len(df_edit)\n",
        "\n",
        "print(f\"Edit Distance Dedup: ÏµúÏ¢Ö ÌÅ¨Í∏∞ {after}, Ï≤òÎ¶¨ ÏãúÍ∞Ñ {elapsed:.2f}s\")\n",
        "\n",
        "print(f\"Edit Distance Dedup: ÏµúÏ¢Ö ÌÅ¨Í∏∞ {after}, Ï≤òÎ¶¨ ÏãúÍ∞Ñ {elapsed:.2f}s\")\n",
        "print(f\"Normalized Matching: Ï§ëÎ≥µ Ï†úÍ±∞ Ï†Ñ {before} ‚Üí Ï†úÍ±∞ ÌõÑ {after}\")\n",
        "print(f\"Ï†úÍ±∞ sample Ïàò: {before - after}\")\n",
        "print(f\"Ï†úÍ±∞ sample ÎπÑÏú®: {(before - after) / before * 100:.2f}%\")\n",
        "\n",
        "# Ï§ëÎ≥µÎç∞Ïù¥ÌÑ∞ ÏòàÏãú Ï∂úÎ†•\n",
        "\n",
        "print(\"\\nüîç Levenshtein Ï§ëÎ≥µ ÏòàÏãú (Í±∞Î¶¨ Ìè¨Ìï®):\")\n",
        "for i, (orig_idx, dup_idx) in enumerate(dup_pairs[:2]):\n",
        "    orig = similar_df.loc[orig_idx]\n",
        "    dup  = similar_df.loc[dup_idx]\n",
        "    # Í±∞Î¶¨ Í≥ÑÏÇ∞\n",
        "    dist = Levenshtein.distance(\n",
        "        orig.instruction + orig.input + orig.output,\n",
        "        dup.instruction  + dup.input  + dup.output\n",
        "    )\n",
        "\n",
        "    print(f\"\\nÏ§ëÎ≥µÎç∞Ïù¥ÌÑ∞ {i+1}: (Distance = {dist})\")\n",
        "    print(\"‚ñ∂ ÏõêÎ≥∏ Instruction:\", orig.instruction)\n",
        "    print(\"‚ñ∂ Duplicate Instruction:\", dup.instruction)\n",
        "    print(\"‚ñ∂ ÏõêÎ≥∏ Input      :\", orig.input)\n",
        "    print(\"‚ñ∂ Duplicate Input      :\", dup.input)\n",
        "    print(\"‚ñ∂ ÏõêÎ≥∏ Output     :\", orig.output)\n",
        "    print(\"‚ñ∂ Duplicate Output     :\", dup.output)\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbRBQr54j5yH",
        "outputId": "33db82ec-ca98-4991-d805-5f67b02acf7f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1544/1544 [00:59<00:00, 25.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edit Distance Dedup: ÏµúÏ¢Ö ÌÅ¨Í∏∞ 833, Ï≤òÎ¶¨ ÏãúÍ∞Ñ 59.47s\n",
            "Edit Distance Dedup: ÏµúÏ¢Ö ÌÅ¨Í∏∞ 833, Ï≤òÎ¶¨ ÏãúÍ∞Ñ 59.47s\n",
            "Normalized Matching: Ï§ëÎ≥µ Ï†úÍ±∞ Ï†Ñ 1544 ‚Üí Ï†úÍ±∞ ÌõÑ 833\n",
            "Ï†úÍ±∞ sample Ïàò: 711\n",
            "Ï†úÍ±∞ sample ÎπÑÏú®: 46.05%\n",
            "\n",
            "üîç Levenshtein Ï§ëÎ≥µ ÏòàÏãú (Í±∞Î¶¨ Ìè¨Ìï®):\n",
            "\n",
            "Ï§ëÎ≥µÎç∞Ïù¥ÌÑ∞ 1: (Distance = 20)\n",
            "‚ñ∂ ÏõêÎ≥∏ Instruction: What is the chemical symbol of iron?\n",
            "‚ñ∂ Duplicate Instruction: Give the chemical symbol for Carbon\n",
            "‚ñ∂ ÏõêÎ≥∏ Input      : \n",
            "‚ñ∂ Duplicate Input      : \n",
            "‚ñ∂ ÏõêÎ≥∏ Output     : The chemical symbol of iron is Fe.\n",
            "‚ñ∂ Duplicate Output     : The chemical symbol for Carbon is C.\n",
            "---\n",
            "\n",
            "Ï§ëÎ≥µÎç∞Ïù¥ÌÑ∞ 2: (Distance = 12)\n",
            "‚ñ∂ ÏõêÎ≥∏ Instruction: Tell us a joke\n",
            "‚ñ∂ Duplicate Instruction: Type out a short joke.\n",
            "‚ñ∂ ÏõêÎ≥∏ Input      : \n",
            "‚ñ∂ Duplicate Input      : \n",
            "‚ñ∂ ÏõêÎ≥∏ Output     : Why don't scientists trust atoms? Because they make up everything!\n",
            "‚ñ∂ Duplicate Output     : Why don't scientists trust atoms? Because they make up everything!\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist = Levenshtein.distance(\n",
        "        \"iron \",\"Carbon\"\n",
        "    )\n",
        "dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRrsyJu6skvC",
        "outputId": "6688d522-beac-41f6-8820-dd739eb3bf8a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}